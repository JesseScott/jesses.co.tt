<!DOCTYPE html>

<!-- HEAD -->
<head>
	<!-- META -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<meta name="Keywords" content="Jesse Scott, jesses.co.tt,
	new media, new media artist, artist, digital artist, creative coder,
	Processing, openFrameworks, Cinder, Touch Designer, Pure Data, Pd,
	theory, creative, ideas">
	<meta name="Description" content="The Website of Jesse Scott">
	<meta name="author" content="Jesse Scott">
	<meta name="distribution" content="Global">

	<!-- TITLE -->
	<title>jesses.co.tt</title>

	<!-- STYLE -->
	<link rel="stylesheet" href="../_css/stylez.css">
	<link rel="stylesheet" href="../_css/bootstrap.min.css">

	<!-- JS -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
	<script src="../_js/bootstrap.min.js"></script>
</head>

<!-- BODY -->
<body>

	<!-- NAVBAR -->
	<nav class="navbar navbar-default navbar-fixed-top" id="navlist">
		<div class="container">
			<div id="navbar" class="navbar-collapse collapse">
				<ol class="breadcrumb">
				  <li><a href="../projects.html">Projects</a></li>
				  <li class="active">2nd Story</li>
				</ol>
			</div>
		</div>
	</nav>

	<!-- CONTAINER -->
	<div style="color: #A8B1B8;" class="container">
		<H1>
			2nd Story
		</H1>
		<br>
		<br>
		<p>
			<strong>2nd Story</strong> was an iOS & Android augmented reality application that I designed and developed for
			<a href="http://www.theonlyanimal.com/"  target="_blank">The Only Animal</a>.
			<br>
			<br>
			The app is designed to be a site-specific experience, with two iterations - <strong>Ghost Light</strong> and <strong>DAREU</strong>.
			<br><br>
			Ghost Light took place in Vancouver's 'Blood Alley', an infamous spot that has seen it's fair share of poverty and addication.
			The Only Animal worked with the Portland Hotel Society and SFU Woodwards to canvas long-time residents of the community to offer stories
			that were geolocated within the alley, and came up with 70+ stories that had taken place over he past 30 years.
			The team then chose 10 of the stories to produce as videos, and I collaborated in the pre-production stage to assess AR target compatibility.
			When the videos were finished and loaded onto the phone, the resulting effect was that, in using the image recognition algorithms that I implemented,
			the user would trigger the video by scanning the area with their device's camera, and the subsequent video would start to play,
			having been shot from exactly the same location that the user was standing in. This effect was both immersive and engaging.
			<br><br>
			The second iteration was DAREU, using the same technology and user experience, but taking place in an underused corner of a parking garage on Granvile Island.
			This time the videos were fictional, designed by students, and particularly focused upon the aesthetic contraints and opportunities of viewing content in this form.
			I mentored the students during the production, and had to make significant changes to the computer vision algrithms to accomodate the vagaries of the location.
			<br>
			<br>
			My role involved designing the user interface and user experience, developing and managing the backend system for content delivery, programming the app for both mobile platforms
			(which involved networking, computer vision, and media playback), and mentoring the production team on best practices for AR/VR content.
			<br>
			<br>
			The project page can be seen
			<a href="http://www.theonlyanimal.com/show/2nd-story"  target="_blank">here</a>
			and the source code can be found on my GitHub for
			<a href="https://github.com/JesseScott/SecondStory-iOS"  target="_blank">iOS</a>
			and
			<a href="https://github.com/JesseScott/SecondStory-Android"  target="_blank">Android</a>.
		</p>
  </div> <!-- end container -->

</body>

</html>
